---
title: "Project Submission"
output: html_document
date: "2024-05-10"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(fpp3)
library(kableExtra)
library(gt)
library(tidyverse)
```

### Import Data
```{r}
base_data = read_csv("qgdp_training.csv")
data = base_data %>% 
  select(Date, 
         `Fishing, Aquaculture and Agriculture, Forestry and Fishing Support Services`) %>% 
  mutate(Date = yearquarter(Date)) %>% 
  rename(FAAFFSS = `Fishing, Aquaculture and Agriculture, Forestry and Fishing Support Services`)
data = as_tsibble(data, index=Date)
rm(list="base_data") #Delete the original dataset

data %>% autoplot() + 
  labs(title="New Zealand Fishing, Aquaculture and Agriculture, Forestry and Fishing Support Services (FAAFFSS) GDP ($ Millions) from 1987Q2 to 2021Q4", x= "Quarter", y="FAAFFSS")
```
# Methodology to Create a Shortlist of Appropriate Candidate ETS Models
```{r}
# Check for missing values
missing_values <- data %>% summarise(across(everything(), ~ sum(is.na(.))))
print(missing_values)
```
## Manual Model Fitting:

Defining ETS Models: Manually specify and fit a variety of ETS models with different combinations of error (E), trend (T), and seasonality (S) components. 

The models are categorized as follows:

Error Component (E): Additive (A) or Multiplicative (M).

Trend Component (T): None (N), Additive (A), Multiplicative (M), or Additive damped (Ad).

Seasonality Component (S): None (N), Additive (A), or Multiplicative (M).

Model Examples: Fit models such as ETS(A, N, N) for Simple Exponential Smoothing, ETS(A, A, N) for Holt's Linear Trend, and ETS(A, A, A) for Additive Holt-Winters, among others.
```{r}
# Manually fit different ETS models
# ETS(A,N,N): Model for simple exponential smoothing (SES)
fit_ann <- data %>% model(ETS(FAAFFSS ~ error("A") + trend("N") + season("N")))
# ETS(M,N,N): SES with multiplicative errors
fit_mnn <- data %>% model(ETS(FAAFFSS ~ error("M") + trend("N") + season("N")))
# ETS(A,A,N): A model for Holt’s linear trend method
fit_aan <- data %>% model(ETS(FAAFFSS ~ error("A") + trend("A") + season("N")))
# ETS(M,A,N): Holt’s linear trend method with multiplicative errors
fit_man <- data %>% model(ETS(FAAFFSS ~ error("M") + trend("A") + season("N")))
fit_amn <- data %>% model(ETS(FAAFFSS ~ error("A") + trend("M") + season("N")))
fit_mmn <- data %>% model(ETS(FAAFFSS ~ error("M") + trend("M") + season("N")))
fit_ana <- data %>% model(ETS(FAAFFSS ~ error("A") + trend("N") + season("A")))
fit_mna <- data %>% model(ETS(FAAFFSS ~ error("M") + trend("N") + season("A")))
fit_aaa <- data %>% model(ETS(FAAFFSS ~ error("A") + trend("A") + season("A")))
fit_maa <- data %>% model(ETS(FAAFFSS ~ error("M") + trend("A") + season("A")))
fit_ama <- data %>% model(ETS(FAAFFSS ~ error("A") + trend("M") + season("A")))
fit_mma <- data %>% model(ETS(FAAFFSS ~ error("M") + trend("M") + season("A")))
fit_anm <- data %>% model(ETS(FAAFFSS ~ error("A") + trend("N") + season("M")))
fit_mnm <- data %>% model(ETS(FAAFFSS ~ error("M") + trend("N") + season("M")))
fit_aam <- data %>% model(ETS(FAAFFSS ~ error("A") + trend("A") + season("M")))
fit_mam <- data %>% model(ETS(FAAFFSS ~ error("M") + trend("A") + season("M")))
fit_amm <- data %>% model(ETS(FAAFFSS ~ error("A") + trend("M") + season("M")))
fit_mmm <- data %>% model(ETS(FAAFFSS ~ error("M") + trend("M") + season("M")))
fit_adn <- data %>% model(ETS(FAAFFSS ~ error("A") + trend("Ad") + season("N")))
fit_mdn <- data %>% model(ETS(FAAFFSS ~ error("M") + trend("Ad") + season("N")))
fit_ada <- data %>% model(ETS(FAAFFSS ~ error("A") + trend("Ad") + season("A")))
fit_mda <- data %>% model(ETS(FAAFFSS ~ error("M") + trend("Ad") + season("A")))
fit_adm <- data %>% model(ETS(FAAFFSS ~ error("A") + trend("Ad") + season("M")))
fit_mdm <- data %>% model(ETS(FAAFFSS ~ error("M") + trend("Ad") + season("M")))
```

## Automatic Model Selection:

Using Automated ETS: Utilize the ETS function to automatically fit the best ETS model based on information criteria like AICc (Akaike Information Criterion corrected for small sample sizes).
```{r}
# Automatically fit the ETS model
fit_auto <- data %>% model(ETS(FAAFFSS))
report(fit_auto)
```
## Model Comparison:

Calculating AICc Values: For each manually fitted model and the automatically selected model, compute the AICc value. The AICc penalizes model complexity to prevent overfitting and is useful for comparing models.

Ranking Models: Create a list of all candidate models along with their AICc values. Sort the models by AICc in ascending order to identify the best-performing models.

Choosing the Lowest AICc Model: Select the model with the lowest AICc value as the best model. This model is expected to balance goodness of fit and model complexity.
```{r}
# Compare models using AICc
aic_values <- bind_rows(
  glance(fit_aaa) %>% mutate(Model = "AAA"),
  glance(fit_ann) %>% mutate(Model = "ANN"),
  glance(fit_mnn) %>% mutate(Model = "MNN"),
  glance(fit_aan) %>% mutate(Model = "AAN"),
  glance(fit_man) %>% mutate(Model = "MAN"),
  glance(fit_amn) %>% mutate(Model = "AMN"),
  glance(fit_mmn) %>% mutate(Model = "MMN"),
  glance(fit_ana) %>% mutate(Model = "ANA"),
  glance(fit_mna) %>% mutate(Model = "MNA"),
  glance(fit_maa) %>% mutate(Model = "MAA"),
  glance(fit_ama) %>% mutate(Model = "AMA"),
  glance(fit_mma) %>% mutate(Model = "MMA"),
  glance(fit_anm) %>% mutate(Model = "ANM"),
  glance(fit_mnm) %>% mutate(Model = "MNM"),
  glance(fit_aam) %>% mutate(Model = "AAM"),
  glance(fit_mam) %>% mutate(Model = "MAM"),
  glance(fit_mmm) %>% mutate(Model = "MMM"),
  glance(fit_amm) %>% mutate(Model = "AMM"),
  glance(fit_adn) %>% mutate(Model = "AAdN"),
  glance(fit_mdn) %>% mutate(Model = "MAdN"),
  glance(fit_ada) %>% mutate(Model = "AAdA"),
  glance(fit_mda) %>% mutate(Model = "MAdA"),
  glance(fit_adm) %>% mutate(Model = "AAdM"),
  glance(fit_mdm) %>% mutate(Model = "MAdM"),
  glance(fit_auto) %>% mutate(Model = "AUTO_MAM"),
) %>% select(Model, AICc) %>% arrange(AICc)

print(aic_values)
```

## Reasons for Selecting the ETS(MAM) Model: Lowest AICc Value

Model Comparison: Among the various manually fitted models and the automatically selected model, ETS(MAM) was found to have the lowest AICc value. The AICc (Akaike Information Criterion corrected for small sample sizes) is a measure of the relative quality of statistical models for a given set of data. It considers both the goodness of fit and the complexity of the model (penalizing for the number of parameters). A lower AICc value indicates a better balance between model fit and complexity.

Statistical Justification: Selecting the model with the lowest AICc helps in minimizing overfitting while ensuring that the model adequately captures the underlying patterns in the data.
```{r}
# Select the best model based on the lowest AICc value
best_model <- fit_mam 
report(best_model)
```

## In an ETS(MAM) model:

E stands for the error term, which is multiplicative.

T stands for the trend component, which is additive.

S stands for the seasonal component, which is multiplicative.

The general form of the ETS(MAM) model equations are:
$$
y_t = (l_{t-1} + b_{t-1})s_{t-m}(1+ϵ_t)
$$
$$
l_t = (l_{t-1} + b_{t-1})(1+αϵ_t)
$$
$$
b_t = b_{t-1} + β(l_{t-1}+b_{t-1})ϵ_t
$$
$$
s_t = s_{t-m} (1+γϵ_t)
$$
Where:

$y_t$ is the observed value at time t.

$l_t$ is the level component at time t.

$b_t$ is the trend component at time t.

$s_t$ is the seasonal component at time t.

α, β, and γ are the smoothing parameters for the level, trend, and seasonal components, respectively.

m is the period of seasonality.

```{r}
# Plot the fitted values
best_model %>% augment()
augment(best_model) %>%
ggplot(aes(x = Date)) +
geom_line(aes(y = FAAFFSS, colour = "Data")) +
geom_line(aes(y = .fitted, colour = "Fitted")) +
guides(colour = guide_legend(title = ""))
```
## Model Diagnostics:

Residual Analysis: Perform residual diagnostics on the selected model to ensure that the residuals behave like white noise (i.e., they are uncorrelated and have constant variance).

Components Decomposition: Decompose the selected model to inspect its components (level, trend, and seasonality) for better understanding and validation.
```{r}
# Residual diagnostics
best_model %>% gg_tsresiduals()

# Components Decomposition
best_model %>%
  components() %>% 
  autoplot()
```


```{r}
# Generate forecasts
forecast_data <- best_model %>% forecast(h = 8)
forecast_data
forecast_data %>% autoplot(data) +
  labs(title = "Forecast for the next 8 quarters", x = "Quarter", y = "FAAFFSS")
```

## Explanation of Prediction Intervals

An advantage of ETS models is that prediction intervals can be constructed.
Prediction intervals will differ between additive and multiplicative error models.

For ETS(A,N/A/Ad,N/A) models prediction distributions are Gaussian.

For ETS(M,N/A/Ad,N/A/M) models prediction distributions are non-Gaussian because of nonlinearity of the state space equations.

Gaussian approximation usually give reasonably accurate results.

If this approximation is not reasonable, we can generate future sample paths conditional on the last estimate of the states, and then to obtain prediction intervals from the percentiles of these simulated future paths.

In the ETS model, the prediction interval is calculated based on the variance of the residuals. The ETS (MAM) model is a multiplicative error model, and the calculation of its prediction interval takes into account the gradual accumulation of prediction errors. Specifically, the prediction interval is calculated through the following steps:

Calculate point prediction value: Based on the parameters of the ETS model and input data at future time points, calculate the future point prediction value.

Estimate the variance of the forecast error: Use the variance of the residuals to estimate the variance of the forecast error. For the multiplicative error model, the variance of the error increases with forecast time.

Calculate the prediction interval: Based on the variance of the prediction error and using the assumption of normal distribution, calculate the prediction interval at different confidence levels.

In R, these steps are completed automatically by the forecast function, we only need to specify the forecast time range h.



## Arima Models

### Explore different ARIMA models

###  Explain any transformations or differencing required

From data autoplot graph, we can see that

1. the seasonal variations are increasing over time which suggests a multiplicative seasonality pattern. So we would do a log transformation to stabilize the variance. This transformation converts multiplicative relationships into additive ones, making the series easier to model.

2. the data seems have seasonal effects that repeat every 4 quarters. So we would also differencing for seasonality to remove this effect.

3.there is an upward trend indicates that the mean of the series is not constant over time. So we would need to do first difference to make the series stationary in terms of the trend. However, as the data have a strong seasonal pattern, we will apply seasonal differencing first, because sometimes the resulting series will be stationary and there will be no need for a further first difference.



```{r}
# Log transform to remove the non-constant variance. 

data %>% 
  autoplot(log(FAAFFSS) ) + 
  labs(x = "x", y = "difference of y") + 
  theme_minimal() 
```
so it moved the large of change in variability. variance roughly constant. 

```{r}
# differencing seasonality

data %>% 
  autoplot(log(FAAFFSS) %>% difference(lag=4)) + 
  labs(x = "x", y = "difference of y") + 
  theme_minimal() 

```


after differencing seasonality,  we can't see any patterns now. we removed the autocorrelation in seasonality. It also shows flat trend and the mean is roughly constant, which suggests we removed the trend by seasonal differencing and we don't need to to first order difference anymore. So we have stationary time series. 


```{r}

# test if now the time series data are stationary and non-seasonaly with KPSS test
data  %>%
  features(FAAFFSS , unitroot_kpss)

data  %>%
  features(difference(log(FAAFFSS), 4) , unitroot_kpss)
```
so we can see the change of kpss after applying the transformation and difference. there is now no evidence against the null hypothesis. which means we get a stationary time series. 

Or we can test how many difference we need to do to get a stationary time series. It shows 1 is enough, which with aligns with what we did. 

```{r}
data %>%
features(FAAFFSS, unitroot_ndiffs)
```

```{r}
data %>%
mutate(log_fa = log(FAAFFSS)) %>%
features(log_fa, feat_stl)
```
```{r}
data %>%
features(FAAFFSS, unitroot_nsdiffs)
```


###  Describe methodology used to create a shortlist of appropriate candidate ARIMA models (Fit both manually & automatically)


Now we will check on the acf and pacf to help us decide appropriate candidate ARIMA models. 

```{r}
data %>%gg_tsdisplay( log(FAAFFSS) %>% difference(4) , plot_type = "partial")

```

For the autoregression process, we check the pacf plot and see that the significant peaks up to 4 and no significant peaks afterwards. it suggest 4 autoregressive terms. 
likewise,for the moving average process, we check the acf plot and see significant peaks up to the order of 3 and no significant peaks afterwards. it suggest 3 moving average terms. 
Now we add the manual fit and automatical fit together. 

```{r}

# Manually and Automatically fit candidate models 
fit <- data %>%
  model(arima_013 = ARIMA(FAAFFSS ~ pdq(0, 1, 3)),
        arima_413 = ARIMA(FAAFFSS ~ pdq(4, 1, 0)),
        stepwise = ARIMA(FAAFFSS),
        search = ARIMA(FAAFFSS, stepwise = FALSE))


```


### Select the best model & explain why



We compare the result of both manual and auto fit ARIMA model and select the model with smallest AICc as the best model. Here we will select the manually fitted one "arima_013" as our best model.  

```{r}

glance(fit) %>% 
  arrange(AICc) %>% 
  select(.model:BIC)
```



```{r}
# Report best model
fit %>%
  select(arima_013) %>%
  report()


```


###  Write the model equation in backshift notation

This specifies an ARIMA(0, 1, 3) model, which means:
p=0: No autoregressive (AR) terms.
d=1: First difference to achieve stationary.
q=3: Three moving average (MA) terms.
Backshift Notation:


$$
W_t = Y_t - Y_{t-1}
$$
The ARIMA(0, 1, 3) model is:

$$
W_t = \epsilon_t - \theta_1 \epsilon_{t-1} - \theta_2 \epsilon_{t-2} - \theta_3 \epsilon_{t-3}
$$

Substituting \( W_t \) gives:

$$
Y_t - Y_{t-1} = \epsilon_t - \theta_1 \epsilon_{t-1} - \theta_2 \epsilon_{t-2} - \theta_3 \epsilon_{t-3}
$$

Rearranging the terms, we get:

$$
Y_t = Y_{t-1} + \epsilon_t - \theta_1 \epsilon_{t-1} - \theta_2 \epsilon_{t-2} - \theta_3 \epsilon_{t-3}
$$

Where:
- \( Y_t \) is the value of the series at time \( t \).
- \( \epsilon_t \) is the white noise error term at time \( t \).
- \( \theta_1, \theta_2, \theta_3 \) are the parameters of the MA terms.

### Produce residual diagnostic plots (ggtsresiduals())

```{r}
# Check residuals
fit %>% 
  select(arima_013) %>%
  gg_tsresiduals()

```


###  Produce forecasts for h=8 quarters

```{r}
fit %>% 
  select(arima_013) %>%
  forecast(h = 8) %>%
  autoplot(data) + 
  theme_minimal()
```


###  Explain how prediction intervals are calculated for the method

Prediction intervals provide a range within which future observations are expected to fall with a certain probability, typically 95%. Here's how prediction intervals are calculated for an ARIMA model:

1. **Forecast Error Variance**: The prediction interval is based on the forecast error variance, which increases with the forecast horizon. For an ARIMA model, the forecast error at time \( t+h \) is calculated using the moving average (MA) process.

2. **Standard Error of Forecast**: For an \( h \)-step ahead forecast, the standard error \( \sigma_h \) can be computed using the residuals of the fitted model and the MA terms.

The standard error \( \sigma_h \) accounts for the model parameters and the white noise variance. It includes the accumulation of forecast uncertainty as the horizon \( h \) increases.

3. **Prediction Interval Formula**:  For a 95% confidence interval, the critical value \( z_{0.025} \) is 1.96. Using the forecasted values and the calculated standard error, construct the prediction intervals. 

$$
\hat{Y}_{t+h} \pm z_{\alpha/2} \cdot \sigma_h
$$

Where:
- \( \hat{Y}_{t+h} \) is the forecasted value for time \( t+h \).
- \( z_{\alpha/2} \) is the critical value from the standard normal distribution for the desired confidence level (e.g., 1.96 for 95% confidence).
- \( \sigma_h \) is the standard error of the \( h \)-step ahead forecast.




## Neural Network Auto Regression Model

To understand how a Neural Network Auto Regression (NNAR) model works, its important to first understand the workings of a standard feed forward neural network.

### Understanding Neural Networks

A neural network is modelled after the way human brains work, in that each thought is a result of multiple different neurons firing. Neural networks act in a similar way, in that each prediction or output of the model is a result of several nodes or "neurons" combining their predictions together to come to a single prediction. In a feedforward neural network, the network is comprised of an input layer which includes the input data being fed into the model, optional hidden layers which taken in the output from the previous layer as input, and an output layer which returns the final prediction. The most basic neural network has no hidden layers, which acts the same as a linear regression model, since each input is given a weight, plus an additional bias (intercept) parameter. Hidden layers take the outputs of their preceding layers as inputs and then take a weighted linear sum of them, and alter them by a non linear function such as sigmoid or relu. These hidden layers allow non linearity to be captured by the model for more complicated relationships.
  
![Example Neural Network](./media/nnet2-1.png)
  
When training a feed forward neural network, each node in the network begins with random weights, which are then adjusted to minimize some metric - in the case of NNAR models this metric is MSE. Each iteration of training updates the weights of each node in the network, and then calculates the MSE of the models predictions when using these weights. The network then uses a process called back propagation to assess each node in the network to find which nodes were responsible for the most error in the result, so that in the next iteration these nodes can have their weights changed more drastically to improve the model as much as possible.

### Understanding the Neural Network Auto Regression Model

NNAR models are neural networks which take lagged values of the time series as inputs to the model in order to make predictions. These NNAR models can have many hidden layers, but we fit ours with just one in order to keep the model from being overly complicated. NNAR models are described by the notation NNAR(p, P, k), where p represents the amount of regular lagged inputs into the model, P represents the number of seasonal lags included as input to the model, and k is the number of neurons in the hidden layer. The easiest way to understand these parameters is by looking at an example.  
  
Say we are fitting an NNAR(3,2,3) model on a dataset with yearly seasonality. Here we have a p parameter of 3, meaning in order to predict $y_n$, we will take the lagged inputs $y_{n-1}, y_{n-2}, y_{n-3}$. Additionally we have the P parameter of 2, meaning we will take the seasonal lags $y_{n-12}, y_{n-24}$. This means our model will have an input layer of 5 nodes which take in the lagged inputs $y_{n-1}, y_{n-2}, y_{n-3}, y_{n-12}, y_{n-24}$. Also since our model has a k parameter of 3, it means there is a hidden layer containing 3 neurons, which each take the outputs from the input layer as their respective inputs.  
  
For our model we use the NNETAR() function to fit an NNAR model for us which will calculate optimal parameters for us. By default the model will determine p by fitting a linear model on the seasonally adjusted time series and taking the optimal number of lags according to AIC. The P parameter will automatically be set to 1, and the k parameter is set to (p + P + 1)/2.

### Model fitting
```{r}
NN.fit = data %>% 
  model(base_model = NNETAR()) %>% 
  report(base_model)

NN.fit %>% gg_tsresiduals()

NN.fit %>% 
  forecast(h=8) %>% 
  autoplot(data) + 
  labs(title="FAAFFSS GDP ($ Millions) Predictions Using NNETAR Models", x= "Quarter", y="FAAFFSS")

```

### Prediction Interval Calculation

Since the NNAR model is not based on a well defined stochastic model, there is not a straightforward method to calculate the prediction interval. To account for this, bootstrapping is done in order to determine the variability for each prediction.  
  
The NNAR(1,1,2) model that we fit to the FAAFFSS data can be written as $y_t = f(z_{t-1}) + \epsilon_t$, where $z_t =  (y_{t-1}, y_{t-4})$ where the errors $\epsilon_t$ are assumed to be normally distributed around zero. Using this assumption, we can use our model to make a prediction for the next time period $y_{t+1}$ and add a bootstrapped error, either drawn from the normal distribution or taken from the sample of errors we saw in the training set. If we do this several times (The forecast function does it 1000 times by default) then we can approximate the prediction interval by finding the band which contains 80% and 95% of (predictions + errors) at the next time period. This process can be repeated for as many forecast periods as we like by using the most recent prediction as the input for the new predictions.





















```{r, include=FALSE}
renv::snapshot()
```

